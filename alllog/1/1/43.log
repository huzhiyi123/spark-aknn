topkPartitionNum cmp 4
type(tmp),tmp[0:100],tmp.shape <class 'numpy.ndarray'> [[20]
 [13]
 [13]
 [13]
 [28]] (1000000, 1) (1000000, 3)
centroids1 (8, 128)
centroids2 (40, 128)
40
print(curdf[0]),curdf.shape (50000,) <class 'pandas.core.series.Series'>
start query
result.count() 10000
end query
l 10000 k 10
recall = cnt/float(l*k) 98359   l 10000 k 10
recall: 0.98359
totalconstructtime 214157.57775306702 kmeanspartitiontime 9586.009979248047 localindexconstructtime 203211.5981578827 globalindexconstructtime 1359.9696159362793
totalsearchtime 19849.08390045166 localsearchtime 19772.18270301819 globalsearchtime 76.90119743347168
hello world testdoublekmeansHnsw





topkPartitionNum cmp 5
type(tmp),tmp[0:100],tmp.shape <class 'numpy.ndarray'> [[20]
 [13]
 [13]
 [13]
 [28]] (1000000, 1) (1000000, 3)
centroids1 (8, 128)
centroids2 (40, 128)
40
Traceback (most recent call last):
  File "/aknn/test/testdoublekmeans.py", line 450, in <module>
    print("topkPartitionNum cmp",i)
  File "/aknn/test/testdoublekmeans.py", line 369, in testdoublekmeansHnswV2
    words_df = sql_context.createDataFrame(df,curschema)
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/sql/context.py", line 307, in createDataFrame
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/sql/session.py", line 748, in createDataFrame
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/sql/session.py", line 430, in _createFromLocal
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/context.py", line 527, in parallelize
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/context.py", line 559, in _serialize_to_jvm
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/serializers.py", line 345, in dump_stream
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/serializers.py", line 142, in dump_stream
  File "/usr/spark-2.4.1/python/lib/pyspark.zip/pyspark/serializers.py", line 161, in _write_with_length
  File "/usr/lib/python3.5/tempfile.py", line 622, in func_wrapper
    return func(*args, **kwargs)
OSError: [Errno 28] No space left on device
maxelement = 100000000
k=10
partitionnum=8
topkPartitionNum=3

sc = 1
m = int(50)
distanceFunction='cosine'
kmeanstrainrate=0.05

efConstruction=35
ef = int(4*22)
usesift=True

kmeanspath="/aknn/kmeans/"

gistlist=["gistpartition.csv","gistcentroids2.csv","gistcentroids1.csv"]  
siftlist=["siftpartition.csv","siftcentroids1.csv","siftcentroids2.csv"]

"""
datapath="/my/siftsmall/"
traindatapath=datapath+"siftsmall_base.fvecs"
querydatapath=datapath+"siftsmall_query.fvecs"
querygroundtruthpath=datapath+"siftsmall_groundtruth.ivecs"
"""
datapath="/data/"
traindatapath=datapath+"sift_base.fvecs"
querydatapath=datapath+"sift_query.fvecs"
querygroundtruthpath=datapath+"sift_groundtruth.ivecs"


gistpath="/data/mnist.hdf5"
# ef=10, efConstruction=200


def initparams():
    global maxelement,k,partitionnum,topkPartitionNum,ef,m,distanceFunction,kmeanstrainraten,efConstruction,usesift
    maxelement = 100000000
    k=10
    partitionnum=8
    topkPartitionNum=3
    sc = 1
    m = int(50)
    distanceFunction='cosine'
    kmeanstrainrate=0.05
    efConstruction=100
    ef = efConstruction
    usesift=Truerecall = cnt/float(l*k) 98359   l 10000 k 10
recall: 0.98359
