nohup: ignoring input
/aknn/alllog/1/1/3.log
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
:: loading settings :: url = jar:file:/usr/spark-2.4.1/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
com.github.jelmerk#hnswlib-spark_2.4_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-99e9a733-0064-4e28-8ff0-b4d55d617791;1.0
	confs: [default]
	found com.github.jelmerk#hnswlib-spark_2.4_2.11;1.0.0 in central
	found com.github.jelmerk#hnswlib-utils;1.0.0 in central
	found com.github.jelmerk#hnswlib-scala_2.11;1.0.0 in central
	found com.github.jelmerk#hnswlib-core;1.0.0 in central
	found org.eclipse.collections#eclipse-collections;9.2.0 in central
	found org.eclipse.collections#eclipse-collections-api;9.2.0 in central
:: resolution report :: resolve 211ms :: artifacts dl 5ms
	:: modules in use:
	com.github.jelmerk#hnswlib-core;1.0.0 from central in [default]
	com.github.jelmerk#hnswlib-scala_2.11;1.0.0 from central in [default]
	com.github.jelmerk#hnswlib-spark_2.4_2.11;1.0.0 from central in [default]
	com.github.jelmerk#hnswlib-utils;1.0.0 from central in [default]
	org.eclipse.collections#eclipse-collections;9.2.0 from central in [default]
	org.eclipse.collections#eclipse-collections-api;9.2.0 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   6   |   0   |   0   |   0   ||   6   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-99e9a733-0064-4e28-8ff0-b4d55d617791
	confs: [default]
	0 artifacts copied, 6 already retrieved (0kB/9ms)
2022-01-24 03:33:14,935 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022-01-24 03:33:16,743 INFO spark.SparkContext: Running Spark version 2.4.1
2022-01-24 03:33:16,769 INFO spark.SparkContext: Submitted application: mytest
2022-01-24 03:33:16,809 INFO spark.SecurityManager: Changing view acls to: root
2022-01-24 03:33:16,809 INFO spark.SecurityManager: Changing modify acls to: root
2022-01-24 03:33:16,809 INFO spark.SecurityManager: Changing view acls groups to: 
2022-01-24 03:33:16,809 INFO spark.SecurityManager: Changing modify acls groups to: 
2022-01-24 03:33:16,809 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2022-01-24 03:33:17,010 INFO util.Utils: Successfully started service 'sparkDriver' on port 7001.
2022-01-24 03:33:17,030 INFO spark.SparkEnv: Registering MapOutputTracker
2022-01-24 03:33:17,044 INFO spark.SparkEnv: Registering BlockManagerMaster
2022-01-24 03:33:17,047 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-01-24 03:33:17,047 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022-01-24 03:33:17,054 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-f9e57eec-3dd0-4845-a2a8-4c04f9c5a205
2022-01-24 03:33:17,068 INFO memory.MemoryStore: MemoryStore started with capacity 2004.6 MB
2022-01-24 03:33:17,078 INFO spark.SparkEnv: Registering OutputCommitCoordinator
2022-01-24 03:33:17,133 INFO util.log: Logging initialized @3558ms
2022-01-24 03:33:17,182 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2022-01-24 03:33:17,196 INFO server.Server: Started @3622ms
2022-01-24 03:33:17,211 INFO server.AbstractConnector: Started ServerConnector@4721aac1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-01-24 03:33:17,211 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
2022-01-24 03:33:17,230 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41010da3{/jobs,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,230 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5fcaa136{/jobs/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,231 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@285e0630{/jobs/job,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,232 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4bfc9787{/jobs/job/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,232 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@41b55cdf{/stages,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,233 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1902bd5f{/stages/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,233 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6345783e{/stages/stage,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,234 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2bf6dc68{/stages/stage/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,235 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@633ad5a0{/stages/pool,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,235 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7bd343d2{/stages/pool/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,235 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4f59974d{/storage,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,236 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52d11752{/storage/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,236 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@67f34f7d{/storage/rdd,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,236 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6df5d82{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,237 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5bf51eb{/environment,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,237 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f8ebd89{/environment/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,238 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22fb99a2{/executors,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,238 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5eb4f332{/executors/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,238 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@217bd106{/executors/threadDump,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,239 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b334255{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,243 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@757bfc18{/static,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,244 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e6ea030{/,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,244 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22151851{/api,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,245 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b01d7a0{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,245 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2de1ed19{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,246 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://localhost:4040
2022-01-24 03:33:17,257 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-spark_2.4_2.11-1.0.0.jar at spark://master:7001/jars/com.github.jelmerk_hnswlib-spark_2.4_2.11-1.0.0.jar with timestamp 1642995197256
2022-01-24 03:33:17,257 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-utils-1.0.0.jar at spark://master:7001/jars/com.github.jelmerk_hnswlib-utils-1.0.0.jar with timestamp 1642995197257
2022-01-24 03:33:17,257 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-scala_2.11-1.0.0.jar at spark://master:7001/jars/com.github.jelmerk_hnswlib-scala_2.11-1.0.0.jar with timestamp 1642995197257
2022-01-24 03:33:17,257 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-core-1.0.0.jar at spark://master:7001/jars/com.github.jelmerk_hnswlib-core-1.0.0.jar with timestamp 1642995197257
2022-01-24 03:33:17,257 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.eclipse.collections_eclipse-collections-9.2.0.jar at spark://master:7001/jars/org.eclipse.collections_eclipse-collections-9.2.0.jar with timestamp 1642995197257
2022-01-24 03:33:17,257 INFO spark.SparkContext: Added JAR file:///root/.ivy2/jars/org.eclipse.collections_eclipse-collections-api-9.2.0.jar at spark://master:7001/jars/org.eclipse.collections_eclipse-collections-api-9.2.0.jar with timestamp 1642995197257
2022-01-24 03:33:17,267 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-spark_2.4_2.11-1.0.0.jar at spark://master:7001/files/com.github.jelmerk_hnswlib-spark_2.4_2.11-1.0.0.jar with timestamp 1642995197267
2022-01-24 03:33:17,268 INFO util.Utils: Copying /root/.ivy2/jars/com.github.jelmerk_hnswlib-spark_2.4_2.11-1.0.0.jar to /tmp/spark-699b1596-d8e1-4cba-9645-61d10932f3da/userFiles-545a2805-2720-4944-a816-35cb690fdc30/com.github.jelmerk_hnswlib-spark_2.4_2.11-1.0.0.jar
2022-01-24 03:33:17,306 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-utils-1.0.0.jar at spark://master:7001/files/com.github.jelmerk_hnswlib-utils-1.0.0.jar with timestamp 1642995197306
2022-01-24 03:33:17,306 INFO util.Utils: Copying /root/.ivy2/jars/com.github.jelmerk_hnswlib-utils-1.0.0.jar to /tmp/spark-699b1596-d8e1-4cba-9645-61d10932f3da/userFiles-545a2805-2720-4944-a816-35cb690fdc30/com.github.jelmerk_hnswlib-utils-1.0.0.jar
2022-01-24 03:33:17,312 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-scala_2.11-1.0.0.jar at spark://master:7001/files/com.github.jelmerk_hnswlib-scala_2.11-1.0.0.jar with timestamp 1642995197312
2022-01-24 03:33:17,312 INFO util.Utils: Copying /root/.ivy2/jars/com.github.jelmerk_hnswlib-scala_2.11-1.0.0.jar to /tmp/spark-699b1596-d8e1-4cba-9645-61d10932f3da/userFiles-545a2805-2720-4944-a816-35cb690fdc30/com.github.jelmerk_hnswlib-scala_2.11-1.0.0.jar
2022-01-24 03:33:17,318 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/com.github.jelmerk_hnswlib-core-1.0.0.jar at spark://master:7001/files/com.github.jelmerk_hnswlib-core-1.0.0.jar with timestamp 1642995197318
2022-01-24 03:33:17,318 INFO util.Utils: Copying /root/.ivy2/jars/com.github.jelmerk_hnswlib-core-1.0.0.jar to /tmp/spark-699b1596-d8e1-4cba-9645-61d10932f3da/userFiles-545a2805-2720-4944-a816-35cb690fdc30/com.github.jelmerk_hnswlib-core-1.0.0.jar
2022-01-24 03:33:17,324 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.eclipse.collections_eclipse-collections-9.2.0.jar at spark://master:7001/files/org.eclipse.collections_eclipse-collections-9.2.0.jar with timestamp 1642995197324
2022-01-24 03:33:17,324 INFO util.Utils: Copying /root/.ivy2/jars/org.eclipse.collections_eclipse-collections-9.2.0.jar to /tmp/spark-699b1596-d8e1-4cba-9645-61d10932f3da/userFiles-545a2805-2720-4944-a816-35cb690fdc30/org.eclipse.collections_eclipse-collections-9.2.0.jar
2022-01-24 03:33:17,348 INFO spark.SparkContext: Added file file:///root/.ivy2/jars/org.eclipse.collections_eclipse-collections-api-9.2.0.jar at spark://master:7001/files/org.eclipse.collections_eclipse-collections-api-9.2.0.jar with timestamp 1642995197348
2022-01-24 03:33:17,348 INFO util.Utils: Copying /root/.ivy2/jars/org.eclipse.collections_eclipse-collections-api-9.2.0.jar to /tmp/spark-699b1596-d8e1-4cba-9645-61d10932f3da/userFiles-545a2805-2720-4944-a816-35cb690fdc30/org.eclipse.collections_eclipse-collections-api-9.2.0.jar
2022-01-24 03:33:17,427 INFO client.StandaloneAppClient$ClientEndpoint: Connecting to master spark://master:7077...
2022-01-24 03:33:17,561 INFO client.TransportClientFactory: Successfully created connection to master/172.21.0.2:7077 after 108 ms (0 ms spent in bootstraps)
2022-01-24 03:33:17,662 INFO cluster.StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220124033317-0009
2022-01-24 03:33:17,667 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/0 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,670 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/0 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,670 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/1 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,671 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/1 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,671 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/2 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,672 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/2 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,673 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/3 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,674 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/3 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,674 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/4 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,675 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/4 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,675 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/5 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,676 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/5 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,676 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/6 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,676 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/6 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,677 INFO client.StandaloneAppClient$ClientEndpoint: Executor added: app-20220124033317-0009/7 on worker-20220123135139-172.21.0.3-18881 (172.21.0.3:18881) with 2 core(s)
2022-01-24 03:33:17,677 INFO cluster.StandaloneSchedulerBackend: Granted executor ID app-20220124033317-0009/7 on hostPort 172.21.0.3:18881 with 2 core(s), 2.0 GB RAM
2022-01-24 03:33:17,678 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 7005.
2022-01-24 03:33:17,678 INFO netty.NettyBlockTransferService: Server created on master:7005
2022-01-24 03:33:17,681 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-01-24 03:33:17,684 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/0 is now RUNNING
2022-01-24 03:33:17,685 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/1 is now RUNNING
2022-01-24 03:33:17,685 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/2 is now RUNNING
2022-01-24 03:33:17,685 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/3 is now RUNNING
2022-01-24 03:33:17,686 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/4 is now RUNNING
2022-01-24 03:33:17,687 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/5 is now RUNNING
2022-01-24 03:33:17,688 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/6 is now RUNNING
2022-01-24 03:33:17,689 INFO client.StandaloneAppClient$ClientEndpoint: Executor updated: app-20220124033317-0009/7 is now RUNNING
2022-01-24 03:33:17,714 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, master, 7005, None)
2022-01-24 03:33:17,719 INFO storage.BlockManagerMasterEndpoint: Registering block manager master:7005 with 2004.6 MB RAM, BlockManagerId(driver, master, 7005, None)
2022-01-24 03:33:17,724 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, master, 7005, None)
2022-01-24 03:33:17,724 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, master, 7005, None)
2022-01-24 03:33:17,739 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@194c88b5{/metrics/json,null,AVAILABLE,@Spark}
2022-01-24 03:33:17,753 INFO cluster.StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2022-01-24 03:33:17,817 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.
2022-01-24 03:33:19,715 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50974) with ID 5
2022-01-24 03:33:19,757 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50972) with ID 1
2022-01-24 03:33:19,762 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50970) with ID 7
2022-01-24 03:33:19,778 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50968) with ID 0
2022-01-24 03:33:19,804 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50982) with ID 2
2022-01-24 03:33:19,809 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50976) with ID 4
2022-01-24 03:33:19,811 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50978) with ID 3
2022-01-24 03:33:19,817 INFO cluster.CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.21.0.3:50980) with ID 6
2022-01-24 03:33:19,848 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7005 with 997.8 MB RAM, BlockManagerId(5, 172.21.0.3, 7005, None)
2022-01-24 03:33:19,871 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7006 with 997.8 MB RAM, BlockManagerId(1, 172.21.0.3, 7006, None)
2022-01-24 03:33:19,898 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7007 with 997.8 MB RAM, BlockManagerId(0, 172.21.0.3, 7007, None)
2022-01-24 03:33:19,919 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7008 with 997.8 MB RAM, BlockManagerId(7, 172.21.0.3, 7008, None)
2022-01-24 03:33:19,931 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7009 with 997.8 MB RAM, BlockManagerId(2, 172.21.0.3, 7009, None)
2022-01-24 03:33:19,956 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7010 with 997.8 MB RAM, BlockManagerId(3, 172.21.0.3, 7010, None)
2022-01-24 03:33:19,981 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7011 with 997.8 MB RAM, BlockManagerId(6, 172.21.0.3, 7011, None)
2022-01-24 03:33:19,982 INFO storage.BlockManagerMasterEndpoint: Registering block manager 172.21.0.3:7012 with 997.8 MB RAM, BlockManagerId(4, 172.21.0.3, 7012, None)
2022-01-24 03:44:00,201 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/tmp/data/newaknn/spark-warehouse').
2022-01-24 03:44:00,202 INFO internal.SharedState: Warehouse path is 'file:/tmp/data/newaknn/spark-warehouse'.
2022-01-24 03:44:00,211 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d99bc5e{/SQL,null,AVAILABLE,@Spark}
2022-01-24 03:44:00,211 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@e973ffe{/SQL/json,null,AVAILABLE,@Spark}
2022-01-24 03:44:00,212 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f3799bd{/SQL/execution,null,AVAILABLE,@Spark}
2022-01-24 03:44:00,212 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4fdc7673{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-01-24 03:44:00,213 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79296869{/static/sql,null,AVAILABLE,@Spark}
2022-01-24 03:44:00,518 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
