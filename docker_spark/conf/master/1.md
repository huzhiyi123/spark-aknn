def setconf(conf):
    conf.set("spark.executor.memory", "1g")
    conf.set("spark.driver.memory","6g")
    conf.set("spark.executor.cores","1")
    conf.set("spark.driver.maxResultSize","2g")
    conf.set("spark.dynamicAllocation.enabled","false")
    conf.set("spark.shuffle.service.enabled", "true")
    conf.set("spark.dynamicAllocation.maxExecutors","16")
    conf.set("executor.instances","8")
    conf.set("spark.task.maxFailures","1")
    conf.set("spark.default.parallelism","8")
    return conf